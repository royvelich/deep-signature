{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ** IMPORT PACKAGES: **"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# python peripherals\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../..'))\n",
    "\n",
    "# scipy\n",
    "import scipy.io\n",
    "import scipy.stats as ss\n",
    "\n",
    "# numpy\n",
    "import numpy\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.collections as mcoll\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ipython\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# deep signature\n",
    "from deep_signature.utils import utils\n",
    "from deep_signature.data_generation.curve_generation import LevelCurvesGenerator\n",
    "from deep_signature.data_manipulation import curve_processing\n",
    "from deep_signature.nn.datasets import DeepSignatureTupletsDataset\n",
    "from deep_signature.nn.networks import DeepSignatureArcLengthNet\n",
    "from deep_signature.nn.losses import ContrastiveLoss\n",
    "from deep_signature.nn.trainers import ModelTrainer\n",
    "from deep_signature.data_manipulation import curve_sampling\n",
    "from deep_signature.data_manipulation import curve_processing\n",
    "\n",
    "# common\n",
    "from common import settings\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ** HELPER FUNCTIONS: **"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "# https://stackoverflow.com/questions/36074455/python-matplotlib-with-a-line-color-gradient-and-colorbar\n",
    "def colorline(ax, x, y, z=None, cmap='copper', norm=plt.Normalize(0.0, 1.0), linewidth=3, alpha=1.0):\n",
    "    \"\"\"\n",
    "    http://nbviewer.ipython.org/github/dpsanders/matplotlib-examples/blob/master/colorline.ipynb\n",
    "    http://matplotlib.org/examples/pylab_examples/multicolored_line.html\n",
    "    Plot a colored line with coordinates x and y\n",
    "    Optionally specify colors in the array z\n",
    "    Optionally specify a colormap, a norm function and a line width\n",
    "    \"\"\"\n",
    "\n",
    "    # Default colors equally spaced on [0,1]:\n",
    "    if z is None:\n",
    "        z = numpy.linspace(0.0, 1.0, len(x))\n",
    "\n",
    "    # Special case if a single number:\n",
    "    # to check for numerical input -- this is a hack\n",
    "    if not hasattr(z, \"__iter__\"):\n",
    "        z = numpy.array([z])\n",
    "\n",
    "    z = numpy.asarray(z)\n",
    "\n",
    "    segments = make_segments(x, y)\n",
    "    lc = mcoll.LineCollection(segments, array=z, cmap=cmap, norm=norm,\n",
    "                              linewidth=linewidth, alpha=alpha)\n",
    "\n",
    "    # ax = plt.gca()\n",
    "    ax.add_collection(lc)\n",
    "\n",
    "    return lc\n",
    "\n",
    "def make_segments(x, y):\n",
    "    \"\"\"\n",
    "    Create list of line segments from x and y coordinates, in the correct format\n",
    "    for LineCollection: an array of the form numlines x (points per line) x 2 (x\n",
    "    and y) array\n",
    "    \"\"\"\n",
    "\n",
    "    points = numpy.array([x, y]).T.reshape(-1, 1, 2)\n",
    "    segments = numpy.concatenate([points[:-1], points[1:]], axis=1)\n",
    "    return segments\n",
    "\n",
    "def plot_dist(ax, dist):\n",
    "    x = numpy.array(range(dist.shape[0]))\n",
    "    y = dist\n",
    "    ax.set_xlim(x.min(), x.max())\n",
    "    ax.set_ylim(y.min(), y.max())\n",
    "    colorline(ax=ax, x=x, y=y, cmap='hsv')\n",
    "\n",
    "def plot_curve_sample(ax, curve, curve_sample, indices, zorder, point_size=10, alpha=1, cmap='hsv'):\n",
    "    x = curve_sample[:, 0]\n",
    "    y = curve_sample[:, 1]\n",
    "    c = numpy.linspace(0.0, 1.0, curve.shape[0])\n",
    "\n",
    "    ax.scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        c=c[indices],\n",
    "        s=point_size,\n",
    "        cmap=cmap,\n",
    "        alpha=alpha,\n",
    "        norm=plt.Normalize(0.0, 1.0),\n",
    "        zorder=zorder)\n",
    "\n",
    "def plot_curve_section_center_point(ax, x, y, zorder, radius=1, color='white'):\n",
    "    circle = plt.Circle((x, y), radius=radius, color=color, zorder=zorder)\n",
    "    ax.add_artist(circle)\n",
    "\n",
    "def plot_curve(ax, curve, linewidth=2, color='red', alpha=1):\n",
    "    x = curve[:, 0]\n",
    "    y = curve[:, 1]\n",
    "    ax.plot(x, y, linewidth=linewidth, color=color, alpha=alpha)\n",
    "\n",
    "def plot_curvature(ax, curvature, color='red', linewidth=2):\n",
    "    x = range(curvature.shape[0])\n",
    "    y = curvature\n",
    "    ax.plot(x, y, color=color, linewidth=linewidth)\n",
    "\n",
    "def plot_sample(ax, sample, color, zorder, point_size=10, alpha=1):\n",
    "    x = sample[:, 0]\n",
    "    y = sample[:, 1]\n",
    "\n",
    "    ax.scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        s=point_size,\n",
    "        color=color,\n",
    "        alpha=alpha,\n",
    "        zorder=zorder)\n",
    "\n",
    "def all_subdirs_of(b='.'):\n",
    "  result = []\n",
    "  for d in os.listdir(b):\n",
    "    bd = os.path.join(b, d)\n",
    "    if os.path.isdir(bd): result.append(bd)\n",
    "  return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ** GLOBAL SETTINGS: **"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.style.use(\"dark_background\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ** SANITY CHECK - CURVES: **"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "curves = LevelCurvesGenerator.load_curves(dir_path=settings.level_curves_dir_path_train)\n",
    "limit = 10\n",
    "color_map = plt.get_cmap('rainbow', limit)\n",
    "for i, curve in enumerate(curves[:limit]): \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(80,40))\n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontsize(30)\n",
    "    ax.axis('equal')\n",
    "    plot_curve(ax=ax, curve=curve, linewidth=5)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ** SANITY CHECK - DATASET PAIRS **"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = DeepSignatureTupletsDataset()\n",
    "dataset.load_dataset(dir_path=settings.level_curves_arclength_tuplets_dir_path)\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "# numpy.random.shuffle(indices)\n",
    "sampler = SubsetRandomSampler(indices)\n",
    "data_loader = DataLoader(dataset, batch_size=1, sampler=sampler)\n",
    "\n",
    "display(HTML('<h3>Random sample of tuplets:</h3>'))\n",
    "for tuplet_index, data in enumerate(data_loader, 0):\n",
    "    if tuplet_index == 35:\n",
    "        break\n",
    "\n",
    "    curve1 = torch.squeeze(torch.squeeze(data['input'])[0])\n",
    "    curve2 = torch.squeeze(torch.squeeze(data['input'])[1])\n",
    "    curve3 = torch.squeeze(torch.squeeze(data['input'])[2])\n",
    "    # curve4 = torch.squeeze(torch.squeeze(data['input'])[3])\n",
    "\n",
    "    display(HTML(f'<h3>Sample #{tuplet_index}:</h3>'))\n",
    "\n",
    "    curve1 = curve1.cpu().numpy()\n",
    "    curve2 = curve2.cpu().numpy()\n",
    "    curve3 = curve3.cpu().numpy()\n",
    "    # curve4 = curve4.cpu().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15,15))\n",
    "    ax.axis('equal')\n",
    "\n",
    "    # print(data['curve'][0].shape)\n",
    "    # print(data['anchor_indices'][0].cpu().numpy())\n",
    "    # print(data['positive_indices1'][0].cpu().numpy())\n",
    "    # print(data['positive_indices2'][0].cpu().numpy())\n",
    "\n",
    "    # plot_curve(ax=ax, curve=data['curve'][0].cpu().numpy(), linewidth=2)\n",
    "\n",
    "    plot_sample(\n",
    "        ax=ax, \n",
    "        sample=curve1, \n",
    "        point_size=30,\n",
    "        color='lightcoral',\n",
    "        zorder=150)\n",
    "\n",
    "    plot_sample(\n",
    "        ax=ax, \n",
    "        sample=curve2, \n",
    "        point_size=20,\n",
    "        color='skyblue',\n",
    "        zorder=50)\n",
    "\n",
    "    plot_sample(\n",
    "        ax=ax, \n",
    "        sample=curve3, \n",
    "        point_size=20,\n",
    "        color='springgreen',\n",
    "        zorder=50)\n",
    "\n",
    "    # print(curve1)\n",
    "    # print(curve2)\n",
    "    # print(curve3)\n",
    "\n",
    "    # plot_sample(\n",
    "    #     ax=ax, \n",
    "    #     sample=curve4, \n",
    "    #     point_size=50,\n",
    "    #     color='gold',\n",
    "    #     zorder=50)\n",
    "\n",
    "    # plot_sample(ax, numpy.array([[0,0]]), point_size=50, alpha=1, color='white', zorder=100)\n",
    "\n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontsize(10)\n",
    "    \n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ** TRAIN/VALIDATION LOSS **"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_subdirs = all_subdirs_of(settings.level_curves_arclength_tuplets_results_dir_path)\n",
    "latest_subdir = os.path.normpath(max(all_subdirs, key=os.path.getmtime))\n",
    "results = numpy.load(f\"{latest_subdir}/results.npy\", allow_pickle=True).item()\n",
    "\n",
    "# results2 = numpy.load(f\"C:/deep-signature-data/level-curves/results/tuplets/arclength/2021-01-14-02-42-52/results.npy\", allow_pickle=True).item()\n",
    "\n",
    "epochs = results['epochs']\n",
    "batch_size = results['batch_size']\n",
    "train_loss_array = results['train_loss_array'][1:]\n",
    "validation_loss_array = results['validation_loss_array'][1:]\n",
    "\n",
    "# train_loss_array2 = results2['train_loss_array']\n",
    "# validation_loss_array2 = results2['validation_loss_array']\n",
    "\n",
    "epochs_list = numpy.array(range(len(train_loss_array)))\n",
    "# epochs_list2 = numpy.array(range(len(train_loss_array2)))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(30,10))\n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "\n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    label.set_fontsize(20)\n",
    "\n",
    "ax.plot(epochs_list, train_loss_array, label='Train Loss', linewidth=4.0)\n",
    "ax.plot(epochs_list, validation_loss_array, label='Validation Loss', linewidth=4.0)\n",
    "\n",
    "# ax.plot(epochs_list2, train_loss_array2, label='Train Loss2', linewidth=4.0)\n",
    "# ax.plot(epochs_list2, validation_loss_array2, label='Validation Loss2', linewidth=4.0)\n",
    "\n",
    "plt.legend(fontsize=20, title_fontsize=20)\n",
    "\n",
    "# print(train_loss_array)\n",
    "# print(validation_loss_array)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ** TEST MODEL **"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_points = 40\n",
    "supporting_points_count = 40\n",
    "max_offset = 4\n",
    "limit = 40\n",
    "numpy.random.seed(60)\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device('cuda')\n",
    "model = DeepSignatureArcLengthNet(sample_points=sample_points).cuda()\n",
    "model.load_state_dict(torch.load(results['model_file_path'], map_location=device))\n",
    "# model.load_state_dict(torch.load(\"C:/deep-signature-data/level-curves/results/tuplets/arclength/2021-01-14-02-42-52/model_349.pt\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "curves = LevelCurvesGenerator.load_curves(dir_path=settings.level_curves_dir_path_train)\n",
    "numpy.random.shuffle(curves)\n",
    "curves = curves[:limit]\n",
    "color_map = plt.get_cmap('rainbow', limit)\n",
    "\n",
    "for curve_index, curve in enumerate(curves):\n",
    "    if curve_index == 25:\n",
    "        break\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "    ax.axis('equal')\n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontsize(10)\n",
    "\n",
    "    # for label in (ax[1].get_xticklabels() + ax[1].get_yticklabels()):\n",
    "    #     label.set_fontsize(30)\n",
    "\n",
    "    # for label in (ax[2].get_xticklabels() + ax[2].get_yticklabels()):\n",
    "    #     label.set_fontsize(30)    \n",
    "\n",
    "    # plot curve\n",
    "    # plot_curve(ax=ax[0], curve=curve, color=color_map(curve_index), linewidth=5)\n",
    "\n",
    "    # plot predicted curvature\n",
    "    predicted_arclength = numpy.zeros(curve.shape[0])\n",
    "    for i in range(curve.shape[0]):\n",
    "        if i == 1:\n",
    "            break\n",
    "\n",
    "        # sample = curve_sampling.sample_curve_section(\n",
    "        #     curve=curve,\n",
    "        #     supporting_points_count=supporting_points_count,\n",
    "        #     start_point_index=i,\n",
    "        #     end_point_index=i+supporting_points_count)\n",
    "        # sample = curve_processing.normalize_curve(curve=sample, force_ccw=False, index1=0, index2=1, center_index=0)\n",
    "        # batch_data = torch.unsqueeze(torch.unsqueeze(torch.from_numpy(sample).double(), dim=0), dim=0).cuda()\n",
    "        # with torch.no_grad():\n",
    "        #     predicted_arclength[i] = torch.squeeze(model(batch_data), dim=0).cpu().detach().numpy()\n",
    "\n",
    "\n",
    "        sample1_org = curve_sampling.sample_curve_section(\n",
    "            curve=curve,\n",
    "            supporting_points_count=sample_points,\n",
    "            start_point_index=i,\n",
    "            end_point_index=i+supporting_points_count - 1)\n",
    "        sample1 = curve_processing.normalize_curve(curve=sample1_org, force_ccw=False, force_end_point=True, index1=0, index2=1, center_index=0)\n",
    "        batch_data1 = torch.unsqueeze(torch.unsqueeze(torch.from_numpy(sample1).double(), dim=0), dim=0).cuda()\n",
    "\n",
    "        sample2_org = curve_sampling.sample_curve_section(\n",
    "            curve=curve,\n",
    "            supporting_points_count=sample_points,\n",
    "            start_point_index=i+supporting_points_count - 1,\n",
    "            end_point_index=i+2*supporting_points_count - 2)\n",
    "        sample2 = curve_processing.normalize_curve(curve=sample2_org, force_ccw=False, force_end_point=True, index1=0, index2=1, center_index=0)\n",
    "        batch_data2 = torch.unsqueeze(torch.unsqueeze(torch.from_numpy(sample2).double(), dim=0), dim=0).cuda()\n",
    "\n",
    "        sample3_org = curve_sampling.sample_curve_section(\n",
    "            curve=curve,\n",
    "            supporting_points_count=sample_points,\n",
    "            start_point_index=i,\n",
    "            end_point_index=i+2*supporting_points_count - 2)\n",
    "        sample3 = curve_processing.normalize_curve(curve=sample3_org, force_ccw=False, force_end_point=True, index1=0, index2=1, center_index=0)\n",
    "        batch_data3 = torch.unsqueeze(torch.unsqueeze(torch.from_numpy(sample3).double(), dim=0), dim=0).cuda()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        sample4_org = curve_sampling.sample_curve_section(\n",
    "            curve=curve,\n",
    "            supporting_points_count=sample_points,\n",
    "            start_point_index=i,\n",
    "            end_point_index=i+supporting_points_count)\n",
    "        sample4 = curve_processing.normalize_curve(curve=sample4_org, force_ccw=False, force_end_point=True, index1=0, index2=1, center_index=0)\n",
    "        batch_data4 = torch.unsqueeze(torch.unsqueeze(torch.from_numpy(sample4).double(), dim=0), dim=0).cuda()\n",
    "\n",
    "        sample5_org = curve_sampling.sample_curve_section(\n",
    "            curve=curve,\n",
    "            supporting_points_count=sample_points,\n",
    "            start_point_index=i,\n",
    "            end_point_index=i+2*supporting_points_count)\n",
    "        sample5 = curve_processing.normalize_curve(curve=sample5_org, force_ccw=False, force_end_point=True, index1=0, index2=1, center_index=0)\n",
    "        batch_data5 = torch.unsqueeze(torch.unsqueeze(torch.from_numpy(sample5).double(), dim=0), dim=0).cuda()\n",
    "\n",
    "\n",
    "        print('------------ 4 + 5 -----------')\n",
    "        with torch.no_grad():\n",
    "            s1 = torch.squeeze(model(batch_data4), dim=0).cpu().detach().numpy()\n",
    "            s2 = torch.squeeze(model(batch_data5), dim=0).cpu().detach().numpy()\n",
    "            print(s1)\n",
    "            print(s2)\n",
    "            print(2 * s1)\n",
    "            print('-----------------------')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        plot_sample(\n",
    "            ax=ax, \n",
    "            sample=sample1, \n",
    "            point_size=20,\n",
    "            color='lightcoral',\n",
    "            alpha=0.5,\n",
    "            zorder=50)\n",
    "\n",
    "        plot_sample(\n",
    "            ax=ax, \n",
    "            sample=sample2, \n",
    "            point_size=20,\n",
    "            color='skyblue',\n",
    "            alpha=0.5,\n",
    "            zorder=50)\n",
    "\n",
    "        plot_sample(\n",
    "            ax=ax, \n",
    "            sample=sample3, \n",
    "            point_size=20,\n",
    "            color='springgreen',\n",
    "            zorder=150)\n",
    "\n",
    "        plot_sample(ax, numpy.array([[sample1[0,0] ,sample1[0, 1]]]), point_size=50, alpha=1, color='white', zorder=200)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            s1 = torch.squeeze(model(batch_data1), dim=0).cpu().detach().numpy()\n",
    "            s2 = torch.squeeze(model(batch_data2), dim=0).cpu().detach().numpy()\n",
    "            s3 = torch.squeeze(model(batch_data3), dim=0).cpu().detach().numpy()\n",
    "            print(s1)\n",
    "            print(s2)\n",
    "            print(s1+s2)\n",
    "            print(s3)\n",
    "            print('-----------------------')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for j in range(60):\n",
    "            sample1 = curve_sampling.sample_curve_section2(\n",
    "                curve=curve,\n",
    "                supporting_points_count=sample_points,\n",
    "                start_point_index=i,\n",
    "                end_point_index=i+supporting_points_count + j)\n",
    "            sample1 = curve_processing.normalize_curve(curve=sample1, force_ccw=False, force_end_point=True, index1=0, index2=1, center_index=0)\n",
    "            batch_data1 = torch.unsqueeze(torch.unsqueeze(torch.from_numpy(sample1).double(), dim=0), dim=0).cuda()\n",
    "            with torch.no_grad():\n",
    "                s1 = torch.squeeze(model(batch_data1), dim=0).cpu().detach().numpy()\n",
    "                print(s1)\n",
    "            \n",
    "        print('-----------------------')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # plot_curvature(ax=ax[1], curvature=predicted_curvature, color=color_map(curve_index), linewidth=5)\n",
    "\n",
    "    # plot ground-truth curvature\n",
    "    # gt_arclength = curve_processing.calculate_arclength(curve=curve)\n",
    "    # plot_curvature(ax=ax[2], curvature=gt_arclength, color=color_map(curve_index), linewidth=5)\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}